{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8047dd37",
   "metadata": {},
   "source": [
    "# Download data set from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cf57faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-1.0.0-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting kagglesdk<1.0,>=0.1.14 (from kagglehub)\n",
      "  Downloading kagglesdk-0.1.15-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in .\\.venv\\Lib\\site-packages (from kagglehub) (26.0)\n",
      "Collecting pyyaml (from kagglehub)\n",
      "  Using cached pyyaml-6.0.3-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting requests (from kagglehub)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tqdm (from kagglehub)\n",
      "  Downloading tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting protobuf (from kagglesdk<1.0,>=0.1.14->kagglehub)\n",
      "  Downloading protobuf-6.33.5-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->kagglehub)\n",
      "  Downloading charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->kagglehub)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->kagglehub)\n",
      "  Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->kagglehub)\n",
      "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: colorama in .\\.venv\\Lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Downloading kagglehub-1.0.0-py3-none-any.whl (70 kB)\n",
      "Downloading kagglesdk-0.1.15-py3-none-any.whl (160 kB)\n",
      "Downloading protobuf-6.33.5-cp310-abi3-win_amd64.whl (437 kB)\n",
      "Using cached pyyaml-6.0.3-cp312-cp312-win_amd64.whl (154 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl (107 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Downloading tqdm-4.67.3-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: urllib3, tqdm, pyyaml, protobuf, idna, charset_normalizer, certifi, requests, kagglesdk, kagglehub\n",
      "\n",
      "   ----------------------------------------  0/10 [urllib3]\n",
      "   ----------------------------------------  0/10 [urllib3]\n",
      "   ----------------------------------------  0/10 [urllib3]\n",
      "   ----------------------------------------  0/10 [urllib3]\n",
      "   ---- -----------------------------------  1/10 [tqdm]\n",
      "   ---- -----------------------------------  1/10 [tqdm]\n",
      "   ---- -----------------------------------  1/10 [tqdm]\n",
      "   ---- -----------------------------------  1/10 [tqdm]\n",
      "   -------- -------------------------------  2/10 [pyyaml]\n",
      "   -------- -------------------------------  2/10 [pyyaml]\n",
      "   ------------ ---------------------------  3/10 [protobuf]\n",
      "   ------------ ---------------------------  3/10 [protobuf]\n",
      "   ------------ ---------------------------  3/10 [protobuf]\n",
      "   ------------ ---------------------------  3/10 [protobuf]\n",
      "   ------------ ---------------------------  3/10 [protobuf]\n",
      "   ------------ ---------------------------  3/10 [protobuf]\n",
      "   ------------ ---------------------------  3/10 [protobuf]\n",
      "   ------------ ---------------------------  3/10 [protobuf]\n",
      "   ---------------- -----------------------  4/10 [idna]\n",
      "   -------------------- -------------------  5/10 [charset_normalizer]\n",
      "   -------------------- -------------------  5/10 [charset_normalizer]\n",
      "   ---------------------------- -----------  7/10 [requests]\n",
      "   ---------------------------- -----------  7/10 [requests]\n",
      "   -------------------------------- -------  8/10 [kagglesdk]\n",
      "   -------------------------------- -------  8/10 [kagglesdk]\n",
      "   -------------------------------- -------  8/10 [kagglesdk]\n",
      "   -------------------------------- -------  8/10 [kagglesdk]\n",
      "   -------------------------------- -------  8/10 [kagglesdk]\n",
      "   -------------------------------- -------  8/10 [kagglesdk]\n",
      "   -------------------------------- -------  8/10 [kagglesdk]\n",
      "   -------------------------------- -------  8/10 [kagglesdk]\n",
      "   -------------------------------- -------  8/10 [kagglesdk]\n",
      "   -------------------------------- -------  8/10 [kagglesdk]\n",
      "   ------------------------------------ ---  9/10 [kagglehub]\n",
      "   ------------------------------------ ---  9/10 [kagglehub]\n",
      "   ------------------------------------ ---  9/10 [kagglehub]\n",
      "   ---------------------------------------- 10/10 [kagglehub]\n",
      "\n",
      "Successfully installed certifi-2026.1.4 charset_normalizer-3.4.4 idna-3.11 kagglehub-1.0.0 kagglesdk-0.1.15 protobuf-6.33.5 pyyaml-6.0.3 requests-2.32.5 tqdm-4.67.3 urllib3-2.6.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89e92e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading to data/1.archive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 173M/173M [00:13<00:00, 13.0MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\n",
    "    \"osamajalilhassan/bone-fracture-dataset\",\n",
    "    output_dir=\"data/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb530cdb",
   "metadata": {},
   "source": [
    "# Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "912dc72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Counts\n",
      "\n",
      "testing\n",
      "  fractured: 360\n",
      "  not_fractured: 240\n",
      "  total: 600\n",
      "\n",
      "training\n",
      "  fractured: 4480\n",
      "  not_fractured: 4383\n",
      "  total: 8863\n",
      "\n",
      "img dimensions\n",
      "unique dimensions: 156\n",
      "  224x224: 9273 images\n",
      "  1353x1693: 16 images\n",
      "  1996x2504: 9 images\n",
      "  1500x1996: 4 images\n",
      "  818x1115: 2 images\n",
      "  1430x1140: 2 images\n",
      "  1352x1692: 2 images\n",
      "  1081x1560: 2 images\n",
      "  1772x1666: 2 images\n",
      "  1382x1932: 2 images\n",
      "   146 more sizes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "\n",
    "data_dir = \"data/BoneFractureDataset\"\n",
    "\n",
    "counts = {}\n",
    "\n",
    "for split in [\"testing\", \"training\"]:\n",
    "    counts[split] = {}\n",
    "    for cls in os.listdir(os.path.join(data_dir, split)):\n",
    "        cls_path = os.path.join(data_dir, split, cls)\n",
    "        if os.path.isdir(cls_path):\n",
    "            counts[split][cls] = len([f for f in os.listdir(cls_path) if not f.startswith(\".\")])\n",
    "\n",
    "\n",
    "#counts \n",
    "print(\"Image Counts\")\n",
    "for split, classes in counts.items():\n",
    "    print(f\"\\n{split}\")\n",
    "    for cls, count in classes.items(): \n",
    "        print(f\"  {cls}: {count}\")\n",
    "    print(f\"  total: {sum(classes.values())}\")\n",
    "\n",
    "\n",
    "#making sure its not cooked \n",
    "print(\"\\nimg dimensions\")\n",
    "sizes = defaultdict(int)\n",
    "errors = []\n",
    "\n",
    "for split in counts:\n",
    "    for cls in counts[split]:\n",
    "        cls_path = os.path.join(data_dir, split, cls)\n",
    "        for fname in os.listdir(cls_path):\n",
    "            fpath = os.path.join(cls_path, fname)\n",
    "            try:\n",
    "                with Image.open(fpath) as img:\n",
    "                    sizes[img.size] += 1\n",
    "            except Exception as e:\n",
    "                errors.append((fpath, str(e)))\n",
    "\n",
    "print(f\"unique dimensions: {len(sizes)}\")\n",
    "for size, count in sorted(sizes.items(), key=lambda x: -x[1])[:10]:\n",
    "    print(f\"  {size[0]}x{size[1]}: {count} images\")\n",
    "\n",
    "if len(sizes) > 10:\n",
    "    print(f\"   {len(sizes) - 10} more sizes\")\n",
    "\n",
    "if errors:\n",
    "    print(f\"\\n{len(errors)} unreadable files:\")\n",
    "    for path, err in errors[:5]:\n",
    "        print(f\"  {path}: {err}\")\n",
    "        print(\"ðŸ¥€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74b710e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
